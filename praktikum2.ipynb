{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import pandas\n",
    "data = pandas.read_csv(\"train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import optuna"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# for neural networks\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.backend import clear_session\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# machine learning basics\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# train_test_split was moved from cross_validation to model_selection in 0.18\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "BATCHSIZE = 100\n",
    "# number of epochs\n",
    "EPOCHS = 10\n",
    "\n",
    "# needed to save best model so far\n",
    "global best_accuracy_so_far"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The objective function for optuna to optimize the hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    global best_accuracy_so_far\n",
    "\n",
    "    # Clear clutter from previous Keras session graphs.\n",
    "    clear_session()\n",
    "\n",
    "    covertype = data\n",
    "\n",
    "    # get features X and labels y\n",
    "    X = data.values[:,1:-1]\n",
    "    y = data['Cover_Type'].values\n",
    "\n",
    "    # split dataset into training and validation datasets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    # Fit only to the training data\n",
    "    scaler.fit(X_train)\n",
    "    # save fitted scaler, because you need it later for the test dataset\n",
    "    pickle.dump(scaler, open(\"scaler.p\", \"wb\"))\n",
    "\n",
    "    # Now apply the transformations to the data:\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "    # create neural network\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Input(shape=54))\n",
    "    model.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=trial.suggest_int(\"units\", 8, 24, step=4), kernel_initializer='uniform',\n",
    "                    activation=trial.suggest_categorical(\"activation\", [\"relu\", \"linear\"])))\n",
    "    # Adding dropout to prevent overfitting\n",
    "    model.add(Dropout(rate=trial.suggest_float(\"rate\", 0.0, 0.1, step=0.1)))\n",
    "    model.add(Dense(10, kernel_initializer='uniform', activation='sigmoid'))\n",
    "\n",
    "    # We compile our model with a sampled learning rate.\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    # train neural network\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        shuffle=True,\n",
    "        batch_size=BATCHSIZE,\n",
    "        epochs=EPOCHS,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    # Evaluate the model accuracy on the validation set.\n",
    "    score = model.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    # save best model so far to be able to use the best model later to predict with test data\n",
    "    if score[1] >= best_accuracy_so_far:\n",
    "        tf.keras.models.save_model(model, '{0}.mdl'.format(trial.number))\n",
    "        best_accuracy_so_far = score[1]\n",
    "\n",
    "    # return accuracy\n",
    "    return score[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Function\n",
    "Use optuna to do hyperparameter optimization to find optimal neural network architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:23:20,575]\u001B[0m A new study created in memory with name: no-name-6007bb5b-add6-4658-9f16-98c92a0c71f9\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 0.mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:23:24,392]\u001B[0m Trial 0 finished with value: 0.29206350445747375 and parameters: {'units': 12, 'activation': 'linear', 'rate': 0.0, 'learning_rate': 2.3957644740303312e-05}. Best is trial 0 with value: 0.29206350445747375.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 1.mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:23:28,311]\u001B[0m Trial 1 finished with value: 0.664814829826355 and parameters: {'units': 12, 'activation': 'relu', 'rate': 0.0, 'learning_rate': 0.0009099653037689419}. Best is trial 1 with value: 0.664814829826355.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:23:31,186]\u001B[0m Trial 2 finished with value: 0.4047619104385376 and parameters: {'units': 20, 'activation': 'linear', 'rate': 0.0, 'learning_rate': 0.00016263633864492386}. Best is trial 1 with value: 0.664814829826355.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 3.mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:23:35,059]\u001B[0m Trial 3 finished with value: 0.6830688118934631 and parameters: {'units': 20, 'activation': 'relu', 'rate': 0.0, 'learning_rate': 0.0008402937552590816}. Best is trial 3 with value: 0.6830688118934631.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:23:38,515]\u001B[0m Trial 4 finished with value: 0.6716931462287903 and parameters: {'units': 12, 'activation': 'linear', 'rate': 0.1, 'learning_rate': 0.0016389309960579475}. Best is trial 3 with value: 0.6830688118934631.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 5.mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:23:42,253]\u001B[0m Trial 5 finished with value: 0.6970899701118469 and parameters: {'units': 16, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.009018541301952095}. Best is trial 5 with value: 0.6970899701118469.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 6.mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:23:46,112]\u001B[0m Trial 6 finished with value: 0.7148148417472839 and parameters: {'units': 12, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.010365263421036783}. Best is trial 6 with value: 0.7148148417472839.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:23:49,272]\u001B[0m Trial 7 finished with value: 0.6637566089630127 and parameters: {'units': 24, 'activation': 'relu', 'rate': 0.0, 'learning_rate': 0.0006443274441388234}. Best is trial 6 with value: 0.7148148417472839.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:23:52,517]\u001B[0m Trial 8 finished with value: 0.36666667461395264 and parameters: {'units': 24, 'activation': 'linear', 'rate': 0.1, 'learning_rate': 2.8329204188749607e-05}. Best is trial 6 with value: 0.7148148417472839.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:23:55,404]\u001B[0m Trial 9 finished with value: 0.6952381134033203 and parameters: {'units': 20, 'activation': 'relu', 'rate': 0.0, 'learning_rate': 0.001066740553895641}. Best is trial 6 with value: 0.7148148417472839.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:23:58,427]\u001B[0m Trial 10 finished with value: 0.602910041809082 and parameters: {'units': 8, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.08067658742648076}. Best is trial 6 with value: 0.7148148417472839.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: 11.mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-12-01 12:24:02,848]\u001B[0m Trial 11 finished with value: 0.7320106029510498 and parameters: {'units': 16, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.017925001870819347}. Best is trial 11 with value: 0.7320106029510498.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:24:06,247]\u001B[0m Trial 12 finished with value: 0.7044973373413086 and parameters: {'units': 16, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.02372029775562968}. Best is trial 11 with value: 0.7320106029510498.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:24:09,553]\u001B[0m Trial 13 finished with value: 0.7164021134376526 and parameters: {'units': 8, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.010033185436571333}. Best is trial 11 with value: 0.7320106029510498.\u001B[0m\n",
      "\u001B[32m[I 2022-12-01 12:24:12,780]\u001B[0m Trial 14 finished with value: 0.658994734287262 and parameters: {'units': 8, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.08752270142893724}. Best is trial 11 with value: 0.7320106029510498.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "best_accuracy_so_far = -100\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "# be cautious with the number of trials: Do not use a number larger than 50\n",
    "# this call starts the hyperparameter optimization process: the above define function \"objective\" is called with\n",
    "# n_trials different hyperparameter combinations\n",
    "study.optimize(objective, n_trials=15, timeout=600)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analyse the best model and use it to predict accuracy on test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "FrozenTrial(number=11, values=[0.7320106029510498], datetime_start=datetime.datetime(2022, 12, 1, 12, 23, 58, 427097), datetime_complete=datetime.datetime(2022, 12, 1, 12, 24, 2, 848088), params={'units': 16, 'activation': 'relu', 'rate': 0.1, 'learning_rate': 0.017925001870819347}, distributions={'units': IntDistribution(high=24, log=False, low=8, step=4), 'activation': CategoricalDistribution(choices=('relu', 'linear')), 'rate': FloatDistribution(high=0.1, log=False, low=0.0, step=0.1), 'learning_rate': FloatDistribution(high=0.1, log=True, low=1e-05, step=None)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=11, state=TrialState.COMPLETE, value=None)\n",
      "  Value: 0.7320106029510498\n",
      "  Params: \n",
      "    units: 16\n",
      "    activation: relu\n",
      "    rate: 0.1\n",
      "    learning_rate: 0.017925001870819347\n"
     ]
    }
   ],
   "source": [
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(trial)\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the best model. This model was saved in the function \"objective\"."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    " best_model = tf.keras.models.load_model('{0}.mdl'.format(trial.number))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Return performance of final model on new data (test data)\n",
    "TODO: only load test data here, that you get a few days before the deadline."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# cancer = load_breast_cancer()\n",
    "\n",
    "# X_test = cancer['data']\n",
    "# y_test = cancer['target']\n",
    "#\n",
    "# scaler = pickle.load(open(\"scaler.p\", \"rb\"))\n",
    "# # important: preprocessing of test dataset has to be the same as for the training dataset\n",
    "# X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predicting the Test set results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# y_pred = best_model.predict(X_test)\n",
    "# print(y_pred)\n",
    "# # create labels out of predictions\n",
    "# y_pred_labels = np.argmax(y_pred, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making the Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(y_test, y_pred_labels)\n",
    "#\n",
    "# print(\"Our accuracy is {}%\".format(((cm[0][0] + cm[1][1]) / cm.sum()) * 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot heatmap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# sns.heatmap(cm, annot=True)\n",
    "# plt.savefig('confmat.png')\n",
    "#\n",
    "# print(classification_report(y_test, y_pred_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
